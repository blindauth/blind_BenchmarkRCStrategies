{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from SimArchs import RCArch\n",
    "from SimArchs import RegArch\n",
    "from SimArchs import SiameseArch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RunSimArchs import train_model \n",
    "from RunSimArchs import prepare_sequences\n",
    "from RunSimArchs import save_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMETERS = {\n",
    "    'filters': 20,\n",
    "    'kernel_size': 21,\n",
    "    'input_length':200,\n",
    "    'pool_size': 20, \n",
    "    'strides': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RC_WRAPPER = RCArch(**PARAMETERS)\n",
    "REG_WRAPPER = RegArch(**PARAMETERS)\n",
    "SIAMESE_WRAPPER = SiameseArch(**PARAMETERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "!densityMotifSimulation.py --seed 1234 --motifNames ELF1_known2 --max-motifs 3 --min-motifs 1 --mean-motifs 2 --seqLength 200  --rc-prob 0.5 --numSeqs 10000\n",
    "!densityMotifSimulation.py --seed 1234 --motifNames GATA_known6 --max-motifs 3 --min-motifs 1 --mean-motifs 2 --seqLength 200 --rc-prob 0.5 --numSeqs 10000\n",
    "!densityMotifSimulation.py --seed 1234 --motifNames RXRA_known1 --max-motifs 3 --min-motifs 1 --mean-motifs 2 --seqLength 200 --rc-prob 0.5 --numSeqs 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_train_mutate, y_test = prepare_sequences(seq_len = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/miniconda3/envs/tf1.15.2/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "12000/12000 [==============================] - 4s 333us/step - loss: 0.7585 - acc: 0.6032 - val_loss: 0.6778 - val_acc: 0.6562\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.6382 - acc: 0.6540 - val_loss: 0.6293 - val_acc: 0.6656\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.6016 - acc: 0.6853 - val_loss: 0.6016 - val_acc: 0.6870\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5724 - acc: 0.7073 - val_loss: 0.5802 - val_acc: 0.7016\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5487 - acc: 0.7256 - val_loss: 0.5600 - val_acc: 0.7177\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5287 - acc: 0.7380 - val_loss: 0.5420 - val_acc: 0.7313\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5129 - acc: 0.7495 - val_loss: 0.5295 - val_acc: 0.7391\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4990 - acc: 0.7596 - val_loss: 0.5185 - val_acc: 0.7471\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4874 - acc: 0.7713 - val_loss: 0.5097 - val_acc: 0.7530\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4772 - acc: 0.7777 - val_loss: 0.4994 - val_acc: 0.7596\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4679 - acc: 0.7862 - val_loss: 0.4900 - val_acc: 0.7707\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4590 - acc: 0.7951 - val_loss: 0.4830 - val_acc: 0.7764\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4516 - acc: 0.8005 - val_loss: 0.4763 - val_acc: 0.7808\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4460 - acc: 0.8043 - val_loss: 0.4740 - val_acc: 0.7823\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4395 - acc: 0.8095 - val_loss: 0.4660 - val_acc: 0.7890\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4336 - acc: 0.8143 - val_loss: 0.4614 - val_acc: 0.7953\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4281 - acc: 0.8188 - val_loss: 0.4580 - val_acc: 0.7974\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4237 - acc: 0.8226 - val_loss: 0.4539 - val_acc: 0.8017\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4208 - acc: 0.8243 - val_loss: 0.4515 - val_acc: 0.8022\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4165 - acc: 0.8274 - val_loss: 0.4476 - val_acc: 0.8075\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4135 - acc: 0.8274 - val_loss: 0.4451 - val_acc: 0.8129\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4101 - acc: 0.8319 - val_loss: 0.4436 - val_acc: 0.8087\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4073 - acc: 0.8338 - val_loss: 0.4399 - val_acc: 0.8156\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4039 - acc: 0.8354 - val_loss: 0.4396 - val_acc: 0.8134\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4015 - acc: 0.8375 - val_loss: 0.4362 - val_acc: 0.8182\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3989 - acc: 0.8398 - val_loss: 0.4344 - val_acc: 0.8196\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3962 - acc: 0.8419 - val_loss: 0.4337 - val_acc: 0.8204\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3942 - acc: 0.8420 - val_loss: 0.4310 - val_acc: 0.8216\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3922 - acc: 0.8437 - val_loss: 0.4311 - val_acc: 0.8207\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3899 - acc: 0.8446 - val_loss: 0.4292 - val_acc: 0.8230\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3886 - acc: 0.8454 - val_loss: 0.4284 - val_acc: 0.8250\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3863 - acc: 0.8473 - val_loss: 0.4275 - val_acc: 0.8258\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3851 - acc: 0.8473 - val_loss: 0.4273 - val_acc: 0.8276\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3852 - acc: 0.8475 - val_loss: 0.4281 - val_acc: 0.8263\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3820 - acc: 0.8492 - val_loss: 0.4241 - val_acc: 0.8286\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3805 - acc: 0.8507 - val_loss: 0.4235 - val_acc: 0.8314\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3793 - acc: 0.8521 - val_loss: 0.4231 - val_acc: 0.8311\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3784 - acc: 0.8514 - val_loss: 0.4243 - val_acc: 0.8304\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3762 - acc: 0.8524 - val_loss: 0.4221 - val_acc: 0.8301\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3748 - acc: 0.8540 - val_loss: 0.4227 - val_acc: 0.8305\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3736 - acc: 0.8545 - val_loss: 0.4214 - val_acc: 0.8336\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3720 - acc: 0.8548 - val_loss: 0.4206 - val_acc: 0.8318\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3713 - acc: 0.8563 - val_loss: 0.4204 - val_acc: 0.8333\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3715 - acc: 0.8568 - val_loss: 0.4230 - val_acc: 0.8313\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3705 - acc: 0.8558 - val_loss: 0.4203 - val_acc: 0.8326\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3679 - acc: 0.8574 - val_loss: 0.4194 - val_acc: 0.8346\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3676 - acc: 0.8581 - val_loss: 0.4195 - val_acc: 0.8346\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3672 - acc: 0.8574 - val_loss: 0.4216 - val_acc: 0.8327\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3674 - acc: 0.8585 - val_loss: 0.4197 - val_acc: 0.8336\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3650 - acc: 0.8604 - val_loss: 0.4214 - val_acc: 0.8322\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3642 - acc: 0.8599 - val_loss: 0.4194 - val_acc: 0.8361\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3640 - acc: 0.8598 - val_loss: 0.4187 - val_acc: 0.8366\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3628 - acc: 0.8617 - val_loss: 0.4181 - val_acc: 0.8364\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3628 - acc: 0.8595 - val_loss: 0.4199 - val_acc: 0.8331\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3611 - acc: 0.8624 - val_loss: 0.4178 - val_acc: 0.8374\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3604 - acc: 0.8624 - val_loss: 0.4180 - val_acc: 0.8363\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3596 - acc: 0.8618 - val_loss: 0.4181 - val_acc: 0.8369\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3596 - acc: 0.8625 - val_loss: 0.4183 - val_acc: 0.8356\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3587 - acc: 0.8624 - val_loss: 0.4179 - val_acc: 0.8356\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3583 - acc: 0.8628 - val_loss: 0.4179 - val_acc: 0.8365\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3574 - acc: 0.8633 - val_loss: 0.4180 - val_acc: 0.8367\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3572 - acc: 0.8635 - val_loss: 0.4180 - val_acc: 0.8371\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3562 - acc: 0.8633 - val_loss: 0.4176 - val_acc: 0.8377\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3572 - acc: 0.8634 - val_loss: 0.4185 - val_acc: 0.8390\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3562 - acc: 0.8646 - val_loss: 0.4203 - val_acc: 0.8366\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3558 - acc: 0.8648 - val_loss: 0.4213 - val_acc: 0.8371\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3554 - acc: 0.8642 - val_loss: 0.4216 - val_acc: 0.8353\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3561 - acc: 0.8632 - val_loss: 0.4184 - val_acc: 0.8370\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3529 - acc: 0.8657 - val_loss: 0.4191 - val_acc: 0.8392\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3526 - acc: 0.8661 - val_loss: 0.4184 - val_acc: 0.8384\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3523 - acc: 0.8665 - val_loss: 0.4181 - val_acc: 0.8374\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3519 - acc: 0.8652 - val_loss: 0.4199 - val_acc: 0.8363\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3516 - acc: 0.8663 - val_loss: 0.4212 - val_acc: 0.8342\n",
      "auroc: 0.8721438987976567\n",
      "auprc: 0.7791948211641335\n",
      "auroc: 0.8719992663187591\n",
      "auprc: 0.7790125444036929\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 1s 66us/step - loss: 0.7013 - acc: 0.6202 - val_loss: 0.6786 - val_acc: 0.6363\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.6541 - acc: 0.6474 - val_loss: 0.6543 - val_acc: 0.6504\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.6289 - acc: 0.6606 - val_loss: 0.6357 - val_acc: 0.6616\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.6055 - acc: 0.6811 - val_loss: 0.6134 - val_acc: 0.6741\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5802 - acc: 0.6988 - val_loss: 0.5880 - val_acc: 0.6973\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5543 - acc: 0.7187 - val_loss: 0.5649 - val_acc: 0.7078\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5301 - acc: 0.7402 - val_loss: 0.5447 - val_acc: 0.7295\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5105 - acc: 0.7548 - val_loss: 0.5261 - val_acc: 0.7441\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4937 - acc: 0.7679 - val_loss: 0.5121 - val_acc: 0.7553\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4806 - acc: 0.7782 - val_loss: 0.5012 - val_acc: 0.7614\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4682 - acc: 0.7870 - val_loss: 0.4908 - val_acc: 0.7703\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4583 - acc: 0.7954 - val_loss: 0.4831 - val_acc: 0.7776\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4500 - acc: 0.8025 - val_loss: 0.4801 - val_acc: 0.7796\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4420 - acc: 0.8070 - val_loss: 0.4700 - val_acc: 0.7881\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4348 - acc: 0.8132 - val_loss: 0.4650 - val_acc: 0.7929\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4289 - acc: 0.8168 - val_loss: 0.4598 - val_acc: 0.7977\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4244 - acc: 0.8202 - val_loss: 0.4551 - val_acc: 0.8019\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4198 - acc: 0.8236 - val_loss: 0.4533 - val_acc: 0.8028\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4154 - acc: 0.8280 - val_loss: 0.4510 - val_acc: 0.8084\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4121 - acc: 0.8314 - val_loss: 0.4478 - val_acc: 0.8065\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4085 - acc: 0.8329 - val_loss: 0.4433 - val_acc: 0.8139\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4059 - acc: 0.8353 - val_loss: 0.4428 - val_acc: 0.8134\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4028 - acc: 0.8367 - val_loss: 0.4416 - val_acc: 0.8150\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4007 - acc: 0.8378 - val_loss: 0.4393 - val_acc: 0.8174\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3981 - acc: 0.8399 - val_loss: 0.4386 - val_acc: 0.8151\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3970 - acc: 0.8408 - val_loss: 0.4358 - val_acc: 0.8183\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3948 - acc: 0.8416 - val_loss: 0.4338 - val_acc: 0.8207\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3925 - acc: 0.8423 - val_loss: 0.4344 - val_acc: 0.8201\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3909 - acc: 0.8432 - val_loss: 0.4343 - val_acc: 0.8193\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3888 - acc: 0.8458 - val_loss: 0.4326 - val_acc: 0.8209\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3874 - acc: 0.8465 - val_loss: 0.4312 - val_acc: 0.8228\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3860 - acc: 0.8479 - val_loss: 0.4306 - val_acc: 0.8246\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3840 - acc: 0.8494 - val_loss: 0.4305 - val_acc: 0.8237\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3828 - acc: 0.8494 - val_loss: 0.4295 - val_acc: 0.8240\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3823 - acc: 0.8493 - val_loss: 0.4279 - val_acc: 0.8239\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3802 - acc: 0.8512 - val_loss: 0.4272 - val_acc: 0.8261\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3792 - acc: 0.8523 - val_loss: 0.4272 - val_acc: 0.8273\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3782 - acc: 0.8525 - val_loss: 0.4291 - val_acc: 0.8253\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3779 - acc: 0.8526 - val_loss: 0.4345 - val_acc: 0.8209\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3769 - acc: 0.8541 - val_loss: 0.4269 - val_acc: 0.8265\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3749 - acc: 0.8549 - val_loss: 0.4277 - val_acc: 0.8253\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3748 - acc: 0.8544 - val_loss: 0.4271 - val_acc: 0.8269\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3730 - acc: 0.8553 - val_loss: 0.4267 - val_acc: 0.8277\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3716 - acc: 0.8564 - val_loss: 0.4245 - val_acc: 0.8302\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3708 - acc: 0.8558 - val_loss: 0.4253 - val_acc: 0.8283\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3704 - acc: 0.8567 - val_loss: 0.4258 - val_acc: 0.8272\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3686 - acc: 0.8570 - val_loss: 0.4244 - val_acc: 0.8289\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3689 - acc: 0.8569 - val_loss: 0.4247 - val_acc: 0.8288\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3677 - acc: 0.8591 - val_loss: 0.4250 - val_acc: 0.8284\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3675 - acc: 0.8576 - val_loss: 0.4264 - val_acc: 0.8280\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3658 - acc: 0.8588 - val_loss: 0.4259 - val_acc: 0.8279\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3654 - acc: 0.8590 - val_loss: 0.4263 - val_acc: 0.8287\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3641 - acc: 0.8603 - val_loss: 0.4243 - val_acc: 0.8297\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3641 - acc: 0.8585 - val_loss: 0.4241 - val_acc: 0.8295\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3642 - acc: 0.8586 - val_loss: 0.4253 - val_acc: 0.8285\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3630 - acc: 0.8604 - val_loss: 0.4243 - val_acc: 0.8300\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3617 - acc: 0.8601 - val_loss: 0.4276 - val_acc: 0.8259\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3614 - acc: 0.8604 - val_loss: 0.4248 - val_acc: 0.8307\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3600 - acc: 0.8621 - val_loss: 0.4246 - val_acc: 0.8310\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3602 - acc: 0.8622 - val_loss: 0.4249 - val_acc: 0.8306\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3591 - acc: 0.8619 - val_loss: 0.4251 - val_acc: 0.8309\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3597 - acc: 0.8621 - val_loss: 0.4281 - val_acc: 0.8293\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3590 - acc: 0.8622 - val_loss: 0.4255 - val_acc: 0.8310\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3578 - acc: 0.8633 - val_loss: 0.4245 - val_acc: 0.8308\n",
      "auroc: 0.8682301167848845\n",
      "auprc: 0.7708235917930595\n",
      "auroc: 0.8678129499832758\n",
      "auprc: 0.7695710791411093\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 1s 73us/step - loss: 0.7307 - acc: 0.6079 - val_loss: 0.6750 - val_acc: 0.6354\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6500 - acc: 0.6403 - val_loss: 0.6477 - val_acc: 0.6489\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.6220 - acc: 0.6667 - val_loss: 0.6252 - val_acc: 0.6672\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5982 - acc: 0.6860 - val_loss: 0.6058 - val_acc: 0.6740\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5760 - acc: 0.7031 - val_loss: 0.5833 - val_acc: 0.6974\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5544 - acc: 0.7203 - val_loss: 0.5637 - val_acc: 0.7103\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5345 - acc: 0.7350 - val_loss: 0.5471 - val_acc: 0.7272\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5160 - acc: 0.7490 - val_loss: 0.5305 - val_acc: 0.7392\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5005 - acc: 0.7603 - val_loss: 0.5206 - val_acc: 0.7475\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4879 - acc: 0.7693 - val_loss: 0.5079 - val_acc: 0.7577\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4766 - acc: 0.7781 - val_loss: 0.5007 - val_acc: 0.7610\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4671 - acc: 0.7844 - val_loss: 0.4882 - val_acc: 0.7730\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4583 - acc: 0.7926 - val_loss: 0.4826 - val_acc: 0.7770\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4510 - acc: 0.7978 - val_loss: 0.4762 - val_acc: 0.7823\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4431 - acc: 0.8038 - val_loss: 0.4700 - val_acc: 0.7906\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4386 - acc: 0.8075 - val_loss: 0.4638 - val_acc: 0.7928\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4322 - acc: 0.8138 - val_loss: 0.4592 - val_acc: 0.7960\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4273 - acc: 0.8165 - val_loss: 0.4555 - val_acc: 0.8055\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4216 - acc: 0.8217 - val_loss: 0.4505 - val_acc: 0.8063\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4159 - acc: 0.8253 - val_loss: 0.4466 - val_acc: 0.8091\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4118 - acc: 0.8279 - val_loss: 0.4438 - val_acc: 0.8121\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4079 - acc: 0.8314 - val_loss: 0.4411 - val_acc: 0.8133\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4047 - acc: 0.8330 - val_loss: 0.4388 - val_acc: 0.8170\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4009 - acc: 0.8363 - val_loss: 0.4363 - val_acc: 0.8199\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3981 - acc: 0.8376 - val_loss: 0.4355 - val_acc: 0.8210\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3952 - acc: 0.8399 - val_loss: 0.4326 - val_acc: 0.8205\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3921 - acc: 0.8421 - val_loss: 0.4312 - val_acc: 0.8244\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3906 - acc: 0.8433 - val_loss: 0.4301 - val_acc: 0.8266\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3880 - acc: 0.8443 - val_loss: 0.4276 - val_acc: 0.8269\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3869 - acc: 0.8458 - val_loss: 0.4264 - val_acc: 0.8294\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3843 - acc: 0.8467 - val_loss: 0.4290 - val_acc: 0.8275\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3843 - acc: 0.8476 - val_loss: 0.4257 - val_acc: 0.8302\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3815 - acc: 0.8494 - val_loss: 0.4245 - val_acc: 0.8331\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3806 - acc: 0.8493 - val_loss: 0.4229 - val_acc: 0.8335\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3788 - acc: 0.8510 - val_loss: 0.4230 - val_acc: 0.8327\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3768 - acc: 0.8521 - val_loss: 0.4230 - val_acc: 0.8333\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3756 - acc: 0.8528 - val_loss: 0.4213 - val_acc: 0.8345\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3741 - acc: 0.8537 - val_loss: 0.4208 - val_acc: 0.8345\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3732 - acc: 0.8543 - val_loss: 0.4213 - val_acc: 0.8343\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3723 - acc: 0.8556 - val_loss: 0.4214 - val_acc: 0.8329\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3722 - acc: 0.8545 - val_loss: 0.4203 - val_acc: 0.8341\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3701 - acc: 0.8556 - val_loss: 0.4221 - val_acc: 0.8329\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3695 - acc: 0.8556 - val_loss: 0.4199 - val_acc: 0.8363\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3689 - acc: 0.8573 - val_loss: 0.4212 - val_acc: 0.8332\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3673 - acc: 0.8578 - val_loss: 0.4194 - val_acc: 0.8361\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3670 - acc: 0.8575 - val_loss: 0.4210 - val_acc: 0.8336\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3673 - acc: 0.8562 - val_loss: 0.4219 - val_acc: 0.8339\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3669 - acc: 0.8578 - val_loss: 0.4209 - val_acc: 0.8350\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3645 - acc: 0.8578 - val_loss: 0.4211 - val_acc: 0.8348\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3641 - acc: 0.8592 - val_loss: 0.4207 - val_acc: 0.8354\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3627 - acc: 0.8598 - val_loss: 0.4194 - val_acc: 0.8376\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3613 - acc: 0.8606 - val_loss: 0.4189 - val_acc: 0.8361\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3627 - acc: 0.8586 - val_loss: 0.4201 - val_acc: 0.8372\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3617 - acc: 0.8595 - val_loss: 0.4208 - val_acc: 0.8344\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3605 - acc: 0.8608 - val_loss: 0.4223 - val_acc: 0.8353\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3593 - acc: 0.8616 - val_loss: 0.4184 - val_acc: 0.8386\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3590 - acc: 0.8617 - val_loss: 0.4237 - val_acc: 0.8368\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3597 - acc: 0.8622 - val_loss: 0.4190 - val_acc: 0.8377\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3576 - acc: 0.8629 - val_loss: 0.4186 - val_acc: 0.8377\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3576 - acc: 0.8621 - val_loss: 0.4212 - val_acc: 0.8384\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3578 - acc: 0.8620 - val_loss: 0.4191 - val_acc: 0.8368\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3562 - acc: 0.8626 - val_loss: 0.4189 - val_acc: 0.8381\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3561 - acc: 0.8632 - val_loss: 0.4188 - val_acc: 0.8393\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3554 - acc: 0.8624 - val_loss: 0.4197 - val_acc: 0.8362\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3554 - acc: 0.8621 - val_loss: 0.4185 - val_acc: 0.8387\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3544 - acc: 0.8643 - val_loss: 0.4206 - val_acc: 0.8363\n",
      "auroc: 0.8720692511290173\n",
      "auprc: 0.7769583161279853\n",
      "auroc: 0.8715043804723129\n",
      "auprc: 0.776025482189998\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 1s 78us/step - loss: 0.7956 - acc: 0.5891 - val_loss: 0.6906 - val_acc: 0.6377\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6575 - acc: 0.6436 - val_loss: 0.6396 - val_acc: 0.6552\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6247 - acc: 0.6654 - val_loss: 0.6198 - val_acc: 0.6692\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6014 - acc: 0.6813 - val_loss: 0.6010 - val_acc: 0.6853\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5801 - acc: 0.7001 - val_loss: 0.5847 - val_acc: 0.6979\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5605 - acc: 0.7157 - val_loss: 0.5664 - val_acc: 0.7129\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5418 - acc: 0.7298 - val_loss: 0.5516 - val_acc: 0.7244\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5254 - acc: 0.7447 - val_loss: 0.5411 - val_acc: 0.7320\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5104 - acc: 0.7564 - val_loss: 0.5250 - val_acc: 0.7449\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4969 - acc: 0.7697 - val_loss: 0.5147 - val_acc: 0.7526\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4849 - acc: 0.7784 - val_loss: 0.5038 - val_acc: 0.7618\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4742 - acc: 0.7859 - val_loss: 0.4955 - val_acc: 0.7690\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4656 - acc: 0.7926 - val_loss: 0.4917 - val_acc: 0.7698\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4574 - acc: 0.7983 - val_loss: 0.4809 - val_acc: 0.7806\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4507 - acc: 0.8029 - val_loss: 0.4796 - val_acc: 0.7787\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4438 - acc: 0.8092 - val_loss: 0.4713 - val_acc: 0.7863\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4385 - acc: 0.8113 - val_loss: 0.4652 - val_acc: 0.7954\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4326 - acc: 0.8170 - val_loss: 0.4608 - val_acc: 0.7989\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4278 - acc: 0.8199 - val_loss: 0.4571 - val_acc: 0.8014\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4233 - acc: 0.8232 - val_loss: 0.4538 - val_acc: 0.8045\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4194 - acc: 0.8249 - val_loss: 0.4517 - val_acc: 0.8041\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4150 - acc: 0.8291 - val_loss: 0.4491 - val_acc: 0.8074\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4119 - acc: 0.8308 - val_loss: 0.4452 - val_acc: 0.8135\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4088 - acc: 0.8316 - val_loss: 0.4429 - val_acc: 0.8123\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4058 - acc: 0.8341 - val_loss: 0.4413 - val_acc: 0.8156\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4026 - acc: 0.8362 - val_loss: 0.4402 - val_acc: 0.8176\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4002 - acc: 0.8376 - val_loss: 0.4372 - val_acc: 0.8193\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3981 - acc: 0.8385 - val_loss: 0.4354 - val_acc: 0.8197\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3954 - acc: 0.8411 - val_loss: 0.4352 - val_acc: 0.8199\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3937 - acc: 0.8425 - val_loss: 0.4329 - val_acc: 0.8220\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3912 - acc: 0.8432 - val_loss: 0.4320 - val_acc: 0.8233\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3901 - acc: 0.8441 - val_loss: 0.4320 - val_acc: 0.8248\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3882 - acc: 0.8450 - val_loss: 0.4308 - val_acc: 0.8239\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3872 - acc: 0.8466 - val_loss: 0.4296 - val_acc: 0.8258\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3859 - acc: 0.8469 - val_loss: 0.4297 - val_acc: 0.8268\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3842 - acc: 0.8487 - val_loss: 0.4287 - val_acc: 0.8262\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3830 - acc: 0.8485 - val_loss: 0.4304 - val_acc: 0.8217\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 21us/step - loss: 0.3820 - acc: 0.8490 - val_loss: 0.4277 - val_acc: 0.8280\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3807 - acc: 0.8494 - val_loss: 0.4275 - val_acc: 0.8290\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3804 - acc: 0.8508 - val_loss: 0.4269 - val_acc: 0.8293\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3787 - acc: 0.8515 - val_loss: 0.4270 - val_acc: 0.8294\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3776 - acc: 0.8526 - val_loss: 0.4265 - val_acc: 0.8283\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3757 - acc: 0.8538 - val_loss: 0.4267 - val_acc: 0.8278\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3757 - acc: 0.8529 - val_loss: 0.4255 - val_acc: 0.8289\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3743 - acc: 0.8543 - val_loss: 0.4250 - val_acc: 0.8300\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3733 - acc: 0.8550 - val_loss: 0.4247 - val_acc: 0.8297\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3719 - acc: 0.8563 - val_loss: 0.4257 - val_acc: 0.8303\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3715 - acc: 0.8571 - val_loss: 0.4247 - val_acc: 0.8303\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3710 - acc: 0.8572 - val_loss: 0.4249 - val_acc: 0.8309\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3697 - acc: 0.8576 - val_loss: 0.4246 - val_acc: 0.8309\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3694 - acc: 0.8573 - val_loss: 0.4264 - val_acc: 0.8293\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3690 - acc: 0.8581 - val_loss: 0.4246 - val_acc: 0.8308\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3672 - acc: 0.8575 - val_loss: 0.4247 - val_acc: 0.8305\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3675 - acc: 0.8579 - val_loss: 0.4237 - val_acc: 0.8321\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3657 - acc: 0.8586 - val_loss: 0.4230 - val_acc: 0.8336\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3645 - acc: 0.8598 - val_loss: 0.4223 - val_acc: 0.8330\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3642 - acc: 0.8599 - val_loss: 0.4232 - val_acc: 0.8329\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3640 - acc: 0.8591 - val_loss: 0.4234 - val_acc: 0.8330\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3625 - acc: 0.8611 - val_loss: 0.4224 - val_acc: 0.8333\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3625 - acc: 0.8609 - val_loss: 0.4236 - val_acc: 0.8340\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3619 - acc: 0.8609 - val_loss: 0.4239 - val_acc: 0.8330\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3609 - acc: 0.8613 - val_loss: 0.4250 - val_acc: 0.8317\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3603 - acc: 0.8613 - val_loss: 0.4253 - val_acc: 0.8326\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3602 - acc: 0.8627 - val_loss: 0.4260 - val_acc: 0.8325\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3609 - acc: 0.8607 - val_loss: 0.4251 - val_acc: 0.8313\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3586 - acc: 0.8620 - val_loss: 0.4235 - val_acc: 0.8344\n",
      "auroc: 0.8694103228800967\n",
      "auprc: 0.7726299839336694\n",
      "auroc: 0.8690331910530417\n",
      "auprc: 0.7720104303526211\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 1s 88us/step - loss: 0.8096 - acc: 0.5844 - val_loss: 0.7074 - val_acc: 0.6247\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6649 - acc: 0.6396 - val_loss: 0.6563 - val_acc: 0.6370\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6337 - acc: 0.6600 - val_loss: 0.6390 - val_acc: 0.6527\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6132 - acc: 0.6753 - val_loss: 0.6237 - val_acc: 0.6677\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5950 - acc: 0.6896 - val_loss: 0.6086 - val_acc: 0.6766\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5766 - acc: 0.7044 - val_loss: 0.5917 - val_acc: 0.6902\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5588 - acc: 0.7190 - val_loss: 0.5756 - val_acc: 0.7070\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5398 - acc: 0.7334 - val_loss: 0.5591 - val_acc: 0.7195\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5215 - acc: 0.7477 - val_loss: 0.5430 - val_acc: 0.7330\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.5055 - acc: 0.7596 - val_loss: 0.5307 - val_acc: 0.7406\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4921 - acc: 0.7684 - val_loss: 0.5206 - val_acc: 0.7502\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4798 - acc: 0.7782 - val_loss: 0.5073 - val_acc: 0.7610\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4699 - acc: 0.7844 - val_loss: 0.4978 - val_acc: 0.7664\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4610 - acc: 0.7916 - val_loss: 0.4901 - val_acc: 0.7728\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4523 - acc: 0.7974 - val_loss: 0.4873 - val_acc: 0.7755\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4462 - acc: 0.8020 - val_loss: 0.4787 - val_acc: 0.7799\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4399 - acc: 0.8058 - val_loss: 0.4740 - val_acc: 0.7849\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4340 - acc: 0.8132 - val_loss: 0.4693 - val_acc: 0.7884\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4287 - acc: 0.8167 - val_loss: 0.4666 - val_acc: 0.7918\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4250 - acc: 0.8196 - val_loss: 0.4619 - val_acc: 0.7946\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4201 - acc: 0.8232 - val_loss: 0.4574 - val_acc: 0.8004\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4164 - acc: 0.8247 - val_loss: 0.4551 - val_acc: 0.8013\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4130 - acc: 0.8266 - val_loss: 0.4522 - val_acc: 0.8066\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4102 - acc: 0.8296 - val_loss: 0.4544 - val_acc: 0.8030\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4082 - acc: 0.8295 - val_loss: 0.4504 - val_acc: 0.8077\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4047 - acc: 0.8324 - val_loss: 0.4491 - val_acc: 0.8078\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4021 - acc: 0.8349 - val_loss: 0.4455 - val_acc: 0.8096\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3998 - acc: 0.8352 - val_loss: 0.4430 - val_acc: 0.8131\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3974 - acc: 0.8357 - val_loss: 0.4417 - val_acc: 0.8146\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3961 - acc: 0.8379 - val_loss: 0.4410 - val_acc: 0.8161\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3936 - acc: 0.8390 - val_loss: 0.4398 - val_acc: 0.8163\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3916 - acc: 0.8401 - val_loss: 0.4387 - val_acc: 0.8161\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3902 - acc: 0.8404 - val_loss: 0.4386 - val_acc: 0.8183\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3888 - acc: 0.8425 - val_loss: 0.4395 - val_acc: 0.8168\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3887 - acc: 0.8414 - val_loss: 0.4365 - val_acc: 0.8201\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3857 - acc: 0.8437 - val_loss: 0.4400 - val_acc: 0.8168\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3853 - acc: 0.8439 - val_loss: 0.4352 - val_acc: 0.8221\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3837 - acc: 0.8446 - val_loss: 0.4363 - val_acc: 0.8207\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3814 - acc: 0.8459 - val_loss: 0.4347 - val_acc: 0.8209\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3802 - acc: 0.8466 - val_loss: 0.4361 - val_acc: 0.8203\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3796 - acc: 0.8486 - val_loss: 0.4322 - val_acc: 0.8235\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3783 - acc: 0.8486 - val_loss: 0.4332 - val_acc: 0.8248\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3770 - acc: 0.8500 - val_loss: 0.4324 - val_acc: 0.8233\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3761 - acc: 0.8498 - val_loss: 0.4313 - val_acc: 0.8253\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3750 - acc: 0.8502 - val_loss: 0.4305 - val_acc: 0.8250\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3746 - acc: 0.8504 - val_loss: 0.4311 - val_acc: 0.8253\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3735 - acc: 0.8508 - val_loss: 0.4307 - val_acc: 0.8254\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3719 - acc: 0.8532 - val_loss: 0.4313 - val_acc: 0.8251\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3709 - acc: 0.8532 - val_loss: 0.4285 - val_acc: 0.8277\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3715 - acc: 0.8536 - val_loss: 0.4313 - val_acc: 0.8258\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3706 - acc: 0.8533 - val_loss: 0.4292 - val_acc: 0.8259\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3683 - acc: 0.8547 - val_loss: 0.4276 - val_acc: 0.8277\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3674 - acc: 0.8554 - val_loss: 0.4282 - val_acc: 0.8274\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3670 - acc: 0.8563 - val_loss: 0.4294 - val_acc: 0.8275\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3668 - acc: 0.8557 - val_loss: 0.4281 - val_acc: 0.8286\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3664 - acc: 0.8558 - val_loss: 0.4272 - val_acc: 0.8288\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3654 - acc: 0.8558 - val_loss: 0.4293 - val_acc: 0.8277\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3644 - acc: 0.8572 - val_loss: 0.4276 - val_acc: 0.8282\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3640 - acc: 0.8570 - val_loss: 0.4284 - val_acc: 0.8294\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3635 - acc: 0.8571 - val_loss: 0.4266 - val_acc: 0.8293\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3624 - acc: 0.8589 - val_loss: 0.4274 - val_acc: 0.8286\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3621 - acc: 0.8596 - val_loss: 0.4269 - val_acc: 0.8292\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3619 - acc: 0.8597 - val_loss: 0.4265 - val_acc: 0.8299\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3608 - acc: 0.8602 - val_loss: 0.4271 - val_acc: 0.8302\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3603 - acc: 0.8606 - val_loss: 0.4270 - val_acc: 0.8303\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3595 - acc: 0.8609 - val_loss: 0.4278 - val_acc: 0.8296\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3596 - acc: 0.8607 - val_loss: 0.4282 - val_acc: 0.8287\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3597 - acc: 0.8608 - val_loss: 0.4268 - val_acc: 0.8288\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3584 - acc: 0.8613 - val_loss: 0.4275 - val_acc: 0.8316\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3588 - acc: 0.8620 - val_loss: 0.4268 - val_acc: 0.8304\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3585 - acc: 0.8605 - val_loss: 0.4296 - val_acc: 0.8302\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3571 - acc: 0.8618 - val_loss: 0.4287 - val_acc: 0.8285\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3568 - acc: 0.8626 - val_loss: 0.4269 - val_acc: 0.8313\n",
      "auroc: 0.867739497075712\n",
      "auprc: 0.7699779025887801\n",
      "auroc: 0.8671052131819884\n",
      "auprc: 0.7690378814651391\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 1s 93us/step - loss: 0.7239 - acc: 0.6127 - val_loss: 0.6790 - val_acc: 0.6407\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6475 - acc: 0.6515 - val_loss: 0.6396 - val_acc: 0.6590\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6141 - acc: 0.6762 - val_loss: 0.6139 - val_acc: 0.6762\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5875 - acc: 0.6969 - val_loss: 0.5891 - val_acc: 0.6934\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.5638 - acc: 0.7143 - val_loss: 0.5678 - val_acc: 0.7088\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5409 - acc: 0.7321 - val_loss: 0.5476 - val_acc: 0.7224\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5207 - acc: 0.7478 - val_loss: 0.5293 - val_acc: 0.7391\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5040 - acc: 0.7611 - val_loss: 0.5153 - val_acc: 0.7510\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4894 - acc: 0.7728 - val_loss: 0.5033 - val_acc: 0.7593\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4777 - acc: 0.7818 - val_loss: 0.4947 - val_acc: 0.7665\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4683 - acc: 0.7887 - val_loss: 0.4868 - val_acc: 0.7727\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4592 - acc: 0.7953 - val_loss: 0.4784 - val_acc: 0.7812\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4500 - acc: 0.8028 - val_loss: 0.4762 - val_acc: 0.7841\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4431 - acc: 0.8076 - val_loss: 0.4710 - val_acc: 0.7881\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4370 - acc: 0.8121 - val_loss: 0.4615 - val_acc: 0.7960\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4312 - acc: 0.8159 - val_loss: 0.4575 - val_acc: 0.7996\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4255 - acc: 0.8202 - val_loss: 0.4535 - val_acc: 0.8035\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4203 - acc: 0.8247 - val_loss: 0.4534 - val_acc: 0.8026\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4183 - acc: 0.8263 - val_loss: 0.4485 - val_acc: 0.8050\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4129 - acc: 0.8297 - val_loss: 0.4443 - val_acc: 0.8107\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4095 - acc: 0.8323 - val_loss: 0.4440 - val_acc: 0.8118\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4068 - acc: 0.8338 - val_loss: 0.4406 - val_acc: 0.8125\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4032 - acc: 0.8356 - val_loss: 0.4384 - val_acc: 0.8157\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.4006 - acc: 0.8371 - val_loss: 0.4390 - val_acc: 0.8140\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3981 - acc: 0.8396 - val_loss: 0.4381 - val_acc: 0.8164\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3961 - acc: 0.8408 - val_loss: 0.4343 - val_acc: 0.8171\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3942 - acc: 0.8419 - val_loss: 0.4336 - val_acc: 0.8196\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3919 - acc: 0.8422 - val_loss: 0.4323 - val_acc: 0.8211\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3903 - acc: 0.8434 - val_loss: 0.4309 - val_acc: 0.8202\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3879 - acc: 0.8439 - val_loss: 0.4307 - val_acc: 0.8219\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3868 - acc: 0.8457 - val_loss: 0.4291 - val_acc: 0.8243\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3852 - acc: 0.8461 - val_loss: 0.4279 - val_acc: 0.8248\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3832 - acc: 0.8481 - val_loss: 0.4286 - val_acc: 0.8240\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3819 - acc: 0.8493 - val_loss: 0.4272 - val_acc: 0.8256\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3806 - acc: 0.8492 - val_loss: 0.4270 - val_acc: 0.8273\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3796 - acc: 0.8506 - val_loss: 0.4263 - val_acc: 0.8284\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3785 - acc: 0.8502 - val_loss: 0.4251 - val_acc: 0.8279\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3780 - acc: 0.8509 - val_loss: 0.4249 - val_acc: 0.8301\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3763 - acc: 0.8520 - val_loss: 0.4258 - val_acc: 0.8289\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3748 - acc: 0.8525 - val_loss: 0.4243 - val_acc: 0.8301\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3738 - acc: 0.8545 - val_loss: 0.4237 - val_acc: 0.8300\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3734 - acc: 0.8528 - val_loss: 0.4267 - val_acc: 0.8284\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3725 - acc: 0.8544 - val_loss: 0.4225 - val_acc: 0.8332\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3709 - acc: 0.8552 - val_loss: 0.4231 - val_acc: 0.8327\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3712 - acc: 0.8549 - val_loss: 0.4249 - val_acc: 0.8291\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3700 - acc: 0.8560 - val_loss: 0.4242 - val_acc: 0.8310\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3695 - acc: 0.8563 - val_loss: 0.4220 - val_acc: 0.8328\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3673 - acc: 0.8577 - val_loss: 0.4239 - val_acc: 0.8303\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3674 - acc: 0.8573 - val_loss: 0.4216 - val_acc: 0.8335\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3661 - acc: 0.8580 - val_loss: 0.4237 - val_acc: 0.8321\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3653 - acc: 0.8587 - val_loss: 0.4223 - val_acc: 0.8326\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3645 - acc: 0.8595 - val_loss: 0.4239 - val_acc: 0.8324\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3644 - acc: 0.8596 - val_loss: 0.4210 - val_acc: 0.8342\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3633 - acc: 0.8593 - val_loss: 0.4234 - val_acc: 0.8324\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3631 - acc: 0.8595 - val_loss: 0.4227 - val_acc: 0.8325\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3635 - acc: 0.8599 - val_loss: 0.4257 - val_acc: 0.8316\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3619 - acc: 0.8600 - val_loss: 0.4199 - val_acc: 0.8346\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3610 - acc: 0.8619 - val_loss: 0.4234 - val_acc: 0.8333\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3617 - acc: 0.8600 - val_loss: 0.4202 - val_acc: 0.8347\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3594 - acc: 0.8618 - val_loss: 0.4204 - val_acc: 0.8356\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3593 - acc: 0.8623 - val_loss: 0.4219 - val_acc: 0.8340\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3581 - acc: 0.8628 - val_loss: 0.4198 - val_acc: 0.8349\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3579 - acc: 0.8629 - val_loss: 0.4204 - val_acc: 0.8347\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3572 - acc: 0.8632 - val_loss: 0.4205 - val_acc: 0.8344\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3567 - acc: 0.8634 - val_loss: 0.4202 - val_acc: 0.8363\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3566 - acc: 0.8623 - val_loss: 0.4208 - val_acc: 0.8352\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3555 - acc: 0.8636 - val_loss: 0.4208 - val_acc: 0.8347\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3559 - acc: 0.8635 - val_loss: 0.4225 - val_acc: 0.8349\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3558 - acc: 0.8634 - val_loss: 0.4215 - val_acc: 0.8358\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3560 - acc: 0.8634 - val_loss: 0.4227 - val_acc: 0.8347\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3553 - acc: 0.8640 - val_loss: 0.4211 - val_acc: 0.8341\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3542 - acc: 0.8643 - val_loss: 0.4208 - val_acc: 0.8351\n",
      "auroc: 0.8705606246142684\n",
      "auprc: 0.7744302393346105\n",
      "auroc: 0.8701366757104859\n",
      "auprc: 0.7736708658321126\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 1s 102us/step - loss: 0.7043 - acc: 0.6201 - val_loss: 0.6626 - val_acc: 0.6502\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6385 - acc: 0.6514 - val_loss: 0.6324 - val_acc: 0.6570\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6066 - acc: 0.6751 - val_loss: 0.6083 - val_acc: 0.6760\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5809 - acc: 0.6952 - val_loss: 0.5857 - val_acc: 0.6927\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5564 - acc: 0.7139 - val_loss: 0.5641 - val_acc: 0.7075\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5349 - acc: 0.7312 - val_loss: 0.5480 - val_acc: 0.7229\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5171 - acc: 0.7453 - val_loss: 0.5320 - val_acc: 0.7323\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5019 - acc: 0.7559 - val_loss: 0.5205 - val_acc: 0.7436\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4895 - acc: 0.7659 - val_loss: 0.5095 - val_acc: 0.7497\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4782 - acc: 0.7753 - val_loss: 0.5039 - val_acc: 0.7582\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4685 - acc: 0.7834 - val_loss: 0.4957 - val_acc: 0.7649\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4605 - acc: 0.7884 - val_loss: 0.4872 - val_acc: 0.7721\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4520 - acc: 0.7959 - val_loss: 0.4799 - val_acc: 0.7770\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4455 - acc: 0.8008 - val_loss: 0.4789 - val_acc: 0.7802\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4390 - acc: 0.8064 - val_loss: 0.4709 - val_acc: 0.7864\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4338 - acc: 0.8102 - val_loss: 0.4654 - val_acc: 0.7923\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4281 - acc: 0.8154 - val_loss: 0.4615 - val_acc: 0.7947\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4235 - acc: 0.8192 - val_loss: 0.4587 - val_acc: 0.7987\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4194 - acc: 0.8226 - val_loss: 0.4585 - val_acc: 0.7981\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4156 - acc: 0.8263 - val_loss: 0.4522 - val_acc: 0.8057\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4117 - acc: 0.8296 - val_loss: 0.4524 - val_acc: 0.8042\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4110 - acc: 0.8302 - val_loss: 0.4470 - val_acc: 0.8093\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4056 - acc: 0.8334 - val_loss: 0.4461 - val_acc: 0.8083\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4026 - acc: 0.8359 - val_loss: 0.4440 - val_acc: 0.8121\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4008 - acc: 0.8369 - val_loss: 0.4416 - val_acc: 0.8134\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3987 - acc: 0.8381 - val_loss: 0.4395 - val_acc: 0.8146\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3960 - acc: 0.8411 - val_loss: 0.4373 - val_acc: 0.8167\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3935 - acc: 0.8430 - val_loss: 0.4375 - val_acc: 0.8166\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3920 - acc: 0.8433 - val_loss: 0.4353 - val_acc: 0.8181\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3898 - acc: 0.8442 - val_loss: 0.4346 - val_acc: 0.8208\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3889 - acc: 0.8449 - val_loss: 0.4359 - val_acc: 0.8195\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3869 - acc: 0.8458 - val_loss: 0.4323 - val_acc: 0.8237\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3847 - acc: 0.8472 - val_loss: 0.4319 - val_acc: 0.8234\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3837 - acc: 0.8483 - val_loss: 0.4319 - val_acc: 0.8228\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3824 - acc: 0.8494 - val_loss: 0.4310 - val_acc: 0.8240\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3806 - acc: 0.8493 - val_loss: 0.4327 - val_acc: 0.8239\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3825 - acc: 0.8498 - val_loss: 0.4391 - val_acc: 0.8188\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3797 - acc: 0.8510 - val_loss: 0.4296 - val_acc: 0.8264\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3773 - acc: 0.8521 - val_loss: 0.4294 - val_acc: 0.8260\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3771 - acc: 0.8521 - val_loss: 0.4291 - val_acc: 0.8264\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3755 - acc: 0.8528 - val_loss: 0.4287 - val_acc: 0.8271\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3747 - acc: 0.8539 - val_loss: 0.4317 - val_acc: 0.8246\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3756 - acc: 0.8538 - val_loss: 0.4316 - val_acc: 0.8262\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3732 - acc: 0.8545 - val_loss: 0.4275 - val_acc: 0.8293\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3717 - acc: 0.8554 - val_loss: 0.4277 - val_acc: 0.8304\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3723 - acc: 0.8551 - val_loss: 0.4318 - val_acc: 0.8255\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3713 - acc: 0.8558 - val_loss: 0.4265 - val_acc: 0.8296\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3692 - acc: 0.8563 - val_loss: 0.4320 - val_acc: 0.8249\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3695 - acc: 0.8563 - val_loss: 0.4271 - val_acc: 0.8301\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3677 - acc: 0.8578 - val_loss: 0.4260 - val_acc: 0.8297\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3670 - acc: 0.8581 - val_loss: 0.4256 - val_acc: 0.8303\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3668 - acc: 0.8585 - val_loss: 0.4274 - val_acc: 0.8307\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3669 - acc: 0.8577 - val_loss: 0.4253 - val_acc: 0.8314\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3653 - acc: 0.8593 - val_loss: 0.4281 - val_acc: 0.8292\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3647 - acc: 0.8593 - val_loss: 0.4260 - val_acc: 0.8307\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3645 - acc: 0.8590 - val_loss: 0.4261 - val_acc: 0.8322\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3635 - acc: 0.8617 - val_loss: 0.4258 - val_acc: 0.8311\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3621 - acc: 0.8609 - val_loss: 0.4266 - val_acc: 0.8324\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3626 - acc: 0.8607 - val_loss: 0.4264 - val_acc: 0.8326\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3619 - acc: 0.8611 - val_loss: 0.4253 - val_acc: 0.8326\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3620 - acc: 0.8607 - val_loss: 0.4287 - val_acc: 0.8299\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3610 - acc: 0.8619 - val_loss: 0.4251 - val_acc: 0.8326\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3601 - acc: 0.8614 - val_loss: 0.4259 - val_acc: 0.8323\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3588 - acc: 0.8628 - val_loss: 0.4244 - val_acc: 0.8333\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3587 - acc: 0.8630 - val_loss: 0.4271 - val_acc: 0.8338\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3582 - acc: 0.8630 - val_loss: 0.4247 - val_acc: 0.8327\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3573 - acc: 0.8631 - val_loss: 0.4250 - val_acc: 0.8343\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3572 - acc: 0.8632 - val_loss: 0.4246 - val_acc: 0.8344\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3561 - acc: 0.8643 - val_loss: 0.4244 - val_acc: 0.8335\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3560 - acc: 0.8645 - val_loss: 0.4253 - val_acc: 0.8346\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3569 - acc: 0.8635 - val_loss: 0.4273 - val_acc: 0.8325\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3558 - acc: 0.8641 - val_loss: 0.4277 - val_acc: 0.8311\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3549 - acc: 0.8651 - val_loss: 0.4263 - val_acc: 0.8319\n",
      "Epoch 74/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3543 - acc: 0.8658 - val_loss: 0.4250 - val_acc: 0.8350\n",
      "auroc: 0.8686234984394021\n",
      "auprc: 0.7714663931765733\n",
      "auroc: 0.868189143211664\n",
      "auprc: 0.7709547107540847\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 1s 113us/step - loss: 0.7175 - acc: 0.6144 - val_loss: 0.6672 - val_acc: 0.6256\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6476 - acc: 0.6436 - val_loss: 0.6423 - val_acc: 0.6505\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6161 - acc: 0.6711 - val_loss: 0.6185 - val_acc: 0.6711\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5890 - acc: 0.6926 - val_loss: 0.5947 - val_acc: 0.6904\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5649 - acc: 0.7094 - val_loss: 0.5761 - val_acc: 0.7046\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5437 - acc: 0.7246 - val_loss: 0.5558 - val_acc: 0.7150\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5267 - acc: 0.7367 - val_loss: 0.5413 - val_acc: 0.7231\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5113 - acc: 0.7473 - val_loss: 0.5299 - val_acc: 0.7341\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4988 - acc: 0.7583 - val_loss: 0.5210 - val_acc: 0.7400\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4898 - acc: 0.7658 - val_loss: 0.5118 - val_acc: 0.7494\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4801 - acc: 0.7730 - val_loss: 0.5036 - val_acc: 0.7569\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4719 - acc: 0.7804 - val_loss: 0.4966 - val_acc: 0.7613\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4651 - acc: 0.7853 - val_loss: 0.4912 - val_acc: 0.7688\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4569 - acc: 0.7926 - val_loss: 0.4851 - val_acc: 0.7726\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.4503 - acc: 0.7985 - val_loss: 0.4797 - val_acc: 0.7793\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4443 - acc: 0.8050 - val_loss: 0.4756 - val_acc: 0.7845\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4383 - acc: 0.8084 - val_loss: 0.4699 - val_acc: 0.7894\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4330 - acc: 0.8131 - val_loss: 0.4673 - val_acc: 0.7916\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4283 - acc: 0.8158 - val_loss: 0.4631 - val_acc: 0.7948\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4237 - acc: 0.8203 - val_loss: 0.4577 - val_acc: 0.7994\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4203 - acc: 0.8214 - val_loss: 0.4549 - val_acc: 0.8027\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4161 - acc: 0.8253 - val_loss: 0.4532 - val_acc: 0.8026\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4124 - acc: 0.8283 - val_loss: 0.4507 - val_acc: 0.8062\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4088 - acc: 0.8306 - val_loss: 0.4499 - val_acc: 0.8063\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4059 - acc: 0.8325 - val_loss: 0.4442 - val_acc: 0.8096\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4040 - acc: 0.8332 - val_loss: 0.4424 - val_acc: 0.8127\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4014 - acc: 0.8352 - val_loss: 0.4428 - val_acc: 0.8128\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3984 - acc: 0.8372 - val_loss: 0.4399 - val_acc: 0.8146\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3971 - acc: 0.8378 - val_loss: 0.4393 - val_acc: 0.8140\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3945 - acc: 0.8403 - val_loss: 0.4379 - val_acc: 0.8145\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3921 - acc: 0.8409 - val_loss: 0.4352 - val_acc: 0.8187\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3908 - acc: 0.8421 - val_loss: 0.4342 - val_acc: 0.8197\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3899 - acc: 0.8429 - val_loss: 0.4361 - val_acc: 0.8194\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3879 - acc: 0.8443 - val_loss: 0.4347 - val_acc: 0.8191\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3879 - acc: 0.8426 - val_loss: 0.4327 - val_acc: 0.8227\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3850 - acc: 0.8451 - val_loss: 0.4307 - val_acc: 0.8232\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3839 - acc: 0.8469 - val_loss: 0.4312 - val_acc: 0.8217\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3834 - acc: 0.8459 - val_loss: 0.4322 - val_acc: 0.8241\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3807 - acc: 0.8492 - val_loss: 0.4288 - val_acc: 0.8245\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3796 - acc: 0.8495 - val_loss: 0.4282 - val_acc: 0.8263\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3794 - acc: 0.8503 - val_loss: 0.4281 - val_acc: 0.8246\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3766 - acc: 0.8528 - val_loss: 0.4293 - val_acc: 0.8232\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3762 - acc: 0.8517 - val_loss: 0.4279 - val_acc: 0.8267\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3752 - acc: 0.8526 - val_loss: 0.4273 - val_acc: 0.8254\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3748 - acc: 0.8524 - val_loss: 0.4273 - val_acc: 0.8269\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3736 - acc: 0.8538 - val_loss: 0.4267 - val_acc: 0.8273\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3723 - acc: 0.8544 - val_loss: 0.4257 - val_acc: 0.8283\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3718 - acc: 0.8539 - val_loss: 0.4309 - val_acc: 0.8248\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3719 - acc: 0.8544 - val_loss: 0.4276 - val_acc: 0.8293\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3704 - acc: 0.8559 - val_loss: 0.4258 - val_acc: 0.8290\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3698 - acc: 0.8548 - val_loss: 0.4259 - val_acc: 0.8288\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3677 - acc: 0.8566 - val_loss: 0.4268 - val_acc: 0.8291\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3677 - acc: 0.8566 - val_loss: 0.4244 - val_acc: 0.8299\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3679 - acc: 0.8555 - val_loss: 0.4244 - val_acc: 0.8301\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3666 - acc: 0.8564 - val_loss: 0.4240 - val_acc: 0.8294\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3661 - acc: 0.8579 - val_loss: 0.4248 - val_acc: 0.8310\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3658 - acc: 0.8567 - val_loss: 0.4241 - val_acc: 0.8298\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3646 - acc: 0.8584 - val_loss: 0.4277 - val_acc: 0.8276\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3641 - acc: 0.8585 - val_loss: 0.4236 - val_acc: 0.8300\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3625 - acc: 0.8590 - val_loss: 0.4237 - val_acc: 0.8319\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3620 - acc: 0.8603 - val_loss: 0.4238 - val_acc: 0.8320\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3603 - acc: 0.8603 - val_loss: 0.4250 - val_acc: 0.8300\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3599 - acc: 0.8611 - val_loss: 0.4241 - val_acc: 0.8320\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3599 - acc: 0.8613 - val_loss: 0.4235 - val_acc: 0.8321\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3586 - acc: 0.8611 - val_loss: 0.4244 - val_acc: 0.8314\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3586 - acc: 0.8606 - val_loss: 0.4240 - val_acc: 0.8316\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3583 - acc: 0.8616 - val_loss: 0.4237 - val_acc: 0.8324\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3568 - acc: 0.8627 - val_loss: 0.4244 - val_acc: 0.8314\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3563 - acc: 0.8618 - val_loss: 0.4235 - val_acc: 0.8329\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3563 - acc: 0.8622 - val_loss: 0.4254 - val_acc: 0.8316\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3559 - acc: 0.8634 - val_loss: 0.4264 - val_acc: 0.8313\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3547 - acc: 0.8638 - val_loss: 0.4230 - val_acc: 0.8332\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3555 - acc: 0.8639 - val_loss: 0.4244 - val_acc: 0.8313\n",
      "Epoch 74/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3534 - acc: 0.8641 - val_loss: 0.4236 - val_acc: 0.8338\n",
      "Epoch 75/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3527 - acc: 0.8650 - val_loss: 0.4255 - val_acc: 0.8330\n",
      "Epoch 76/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3538 - acc: 0.8635 - val_loss: 0.4245 - val_acc: 0.8337\n",
      "Epoch 77/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3522 - acc: 0.8643 - val_loss: 0.4268 - val_acc: 0.8310\n",
      "Epoch 78/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3521 - acc: 0.8634 - val_loss: 0.4294 - val_acc: 0.8323\n",
      "Epoch 79/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3521 - acc: 0.8652 - val_loss: 0.4244 - val_acc: 0.8338\n",
      "Epoch 80/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3514 - acc: 0.8656 - val_loss: 0.4250 - val_acc: 0.8319\n",
      "Epoch 81/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3495 - acc: 0.8675 - val_loss: 0.4241 - val_acc: 0.8340\n",
      "Epoch 82/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3516 - acc: 0.8643 - val_loss: 0.4240 - val_acc: 0.8329\n",
      "auroc: 0.869520486742343\n",
      "auprc: 0.7706251980683074\n",
      "auroc: 0.8691575400961944\n",
      "auprc: 0.77059951337447\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 1s 120us/step - loss: 1.0175 - acc: 0.5528 - val_loss: 0.6989 - val_acc: 0.6374\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6752 - acc: 0.6525 - val_loss: 0.6520 - val_acc: 0.6345\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6298 - acc: 0.6566 - val_loss: 0.6271 - val_acc: 0.6614\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6026 - acc: 0.6812 - val_loss: 0.6042 - val_acc: 0.6790\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5754 - acc: 0.7018 - val_loss: 0.5786 - val_acc: 0.7003\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5489 - acc: 0.7234 - val_loss: 0.5543 - val_acc: 0.7171\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5259 - acc: 0.7412 - val_loss: 0.5363 - val_acc: 0.7327\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5094 - acc: 0.7537 - val_loss: 0.5231 - val_acc: 0.7440\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4965 - acc: 0.7651 - val_loss: 0.5131 - val_acc: 0.7467\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4865 - acc: 0.7709 - val_loss: 0.5133 - val_acc: 0.7517\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4770 - acc: 0.7774 - val_loss: 0.4988 - val_acc: 0.7611\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4688 - acc: 0.7840 - val_loss: 0.4947 - val_acc: 0.7664\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4620 - acc: 0.7900 - val_loss: 0.4893 - val_acc: 0.7715\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.4563 - acc: 0.7937 - val_loss: 0.4832 - val_acc: 0.7737\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4508 - acc: 0.7984 - val_loss: 0.4794 - val_acc: 0.7773\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4463 - acc: 0.8022 - val_loss: 0.4752 - val_acc: 0.7816\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4423 - acc: 0.8068 - val_loss: 0.4718 - val_acc: 0.7824\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4375 - acc: 0.8109 - val_loss: 0.4700 - val_acc: 0.7900\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4340 - acc: 0.8135 - val_loss: 0.4662 - val_acc: 0.7906\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4305 - acc: 0.8155 - val_loss: 0.4621 - val_acc: 0.7932\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4266 - acc: 0.8190 - val_loss: 0.4595 - val_acc: 0.7977\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4229 - acc: 0.8218 - val_loss: 0.4571 - val_acc: 0.7991\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4201 - acc: 0.8242 - val_loss: 0.4561 - val_acc: 0.8010\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4166 - acc: 0.8263 - val_loss: 0.4517 - val_acc: 0.8036\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4145 - acc: 0.8289 - val_loss: 0.4495 - val_acc: 0.8079\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4123 - acc: 0.8307 - val_loss: 0.4518 - val_acc: 0.8025\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.4103 - acc: 0.8311 - val_loss: 0.4456 - val_acc: 0.8099\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4064 - acc: 0.8334 - val_loss: 0.4441 - val_acc: 0.8117\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4037 - acc: 0.8357 - val_loss: 0.4421 - val_acc: 0.8126\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.4019 - acc: 0.8374 - val_loss: 0.4417 - val_acc: 0.8152\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.4001 - acc: 0.8390 - val_loss: 0.4402 - val_acc: 0.8151\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3978 - acc: 0.8407 - val_loss: 0.4411 - val_acc: 0.8166\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3963 - acc: 0.8411 - val_loss: 0.4370 - val_acc: 0.8192\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3942 - acc: 0.8423 - val_loss: 0.4364 - val_acc: 0.8189\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3921 - acc: 0.8441 - val_loss: 0.4356 - val_acc: 0.8183\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3907 - acc: 0.8437 - val_loss: 0.4339 - val_acc: 0.8208\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3901 - acc: 0.8444 - val_loss: 0.4351 - val_acc: 0.8210\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3883 - acc: 0.8460 - val_loss: 0.4335 - val_acc: 0.8202\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3872 - acc: 0.8474 - val_loss: 0.4326 - val_acc: 0.8208\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3850 - acc: 0.8476 - val_loss: 0.4308 - val_acc: 0.8240\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3842 - acc: 0.8490 - val_loss: 0.4302 - val_acc: 0.8226\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3827 - acc: 0.8493 - val_loss: 0.4317 - val_acc: 0.8239\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3815 - acc: 0.8509 - val_loss: 0.4290 - val_acc: 0.8243\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3800 - acc: 0.8509 - val_loss: 0.4284 - val_acc: 0.8248\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3791 - acc: 0.8514 - val_loss: 0.4284 - val_acc: 0.8249\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3780 - acc: 0.8527 - val_loss: 0.4301 - val_acc: 0.8241\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3773 - acc: 0.8527 - val_loss: 0.4279 - val_acc: 0.8273\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3763 - acc: 0.8532 - val_loss: 0.4285 - val_acc: 0.8256\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3758 - acc: 0.8536 - val_loss: 0.4264 - val_acc: 0.8266\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3741 - acc: 0.8547 - val_loss: 0.4272 - val_acc: 0.8257\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3743 - acc: 0.8537 - val_loss: 0.4269 - val_acc: 0.8281\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3730 - acc: 0.8542 - val_loss: 0.4290 - val_acc: 0.8268\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3721 - acc: 0.8551 - val_loss: 0.4281 - val_acc: 0.8248\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3704 - acc: 0.8568 - val_loss: 0.4270 - val_acc: 0.8269\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3707 - acc: 0.8563 - val_loss: 0.4257 - val_acc: 0.8270\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3693 - acc: 0.8568 - val_loss: 0.4247 - val_acc: 0.8289\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3681 - acc: 0.8573 - val_loss: 0.4256 - val_acc: 0.8275\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3672 - acc: 0.8585 - val_loss: 0.4251 - val_acc: 0.8299\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3670 - acc: 0.8576 - val_loss: 0.4244 - val_acc: 0.8292\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3655 - acc: 0.8582 - val_loss: 0.4249 - val_acc: 0.8303\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3647 - acc: 0.8593 - val_loss: 0.4266 - val_acc: 0.8275\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3643 - acc: 0.8596 - val_loss: 0.4249 - val_acc: 0.8301\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3640 - acc: 0.8598 - val_loss: 0.4248 - val_acc: 0.8305\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3625 - acc: 0.8601 - val_loss: 0.4243 - val_acc: 0.8305\n",
      "Epoch 65/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3625 - acc: 0.8605 - val_loss: 0.4249 - val_acc: 0.8299\n",
      "Epoch 66/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3639 - acc: 0.8596 - val_loss: 0.4290 - val_acc: 0.8317\n",
      "Epoch 67/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3618 - acc: 0.8605 - val_loss: 0.4260 - val_acc: 0.8294\n",
      "Epoch 68/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3604 - acc: 0.8615 - val_loss: 0.4252 - val_acc: 0.8304\n",
      "Epoch 69/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3596 - acc: 0.8619 - val_loss: 0.4258 - val_acc: 0.8307\n",
      "Epoch 70/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3589 - acc: 0.8628 - val_loss: 0.4250 - val_acc: 0.8306\n",
      "Epoch 71/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3576 - acc: 0.8632 - val_loss: 0.4249 - val_acc: 0.8307\n",
      "Epoch 72/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3573 - acc: 0.8633 - val_loss: 0.4248 - val_acc: 0.8305\n",
      "Epoch 73/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3571 - acc: 0.8623 - val_loss: 0.4245 - val_acc: 0.8324\n",
      "Epoch 74/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3564 - acc: 0.8633 - val_loss: 0.4251 - val_acc: 0.8323\n",
      "auroc: 0.8682466648531059\n",
      "auprc: 0.7707926761418076\n",
      "auroc: 0.8679598508357413\n",
      "auprc: 0.7705648893334193\n",
      "Train on 12000 samples, validate on 9000 samples\n",
      "Epoch 1/200\n",
      "12000/12000 [==============================] - 2s 127us/step - loss: 0.7170 - acc: 0.6074 - val_loss: 0.6758 - val_acc: 0.6123\n",
      "Epoch 2/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6528 - acc: 0.6434 - val_loss: 0.6452 - val_acc: 0.6427\n",
      "Epoch 3/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6265 - acc: 0.6638 - val_loss: 0.6264 - val_acc: 0.6587\n",
      "Epoch 4/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.6050 - acc: 0.6813 - val_loss: 0.6089 - val_acc: 0.6755\n",
      "Epoch 5/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5841 - acc: 0.6940 - val_loss: 0.5902 - val_acc: 0.6909\n",
      "Epoch 6/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5633 - acc: 0.7099 - val_loss: 0.5723 - val_acc: 0.7052\n",
      "Epoch 7/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5447 - acc: 0.7233 - val_loss: 0.5547 - val_acc: 0.7173\n",
      "Epoch 8/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5280 - acc: 0.7348 - val_loss: 0.5412 - val_acc: 0.7259\n",
      "Epoch 9/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.5112 - acc: 0.7477 - val_loss: 0.5290 - val_acc: 0.7370\n",
      "Epoch 10/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4977 - acc: 0.7579 - val_loss: 0.5170 - val_acc: 0.7441\n",
      "Epoch 11/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4861 - acc: 0.7669 - val_loss: 0.5072 - val_acc: 0.7525\n",
      "Epoch 12/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4752 - acc: 0.7768 - val_loss: 0.5008 - val_acc: 0.7603\n",
      "Epoch 13/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.4655 - acc: 0.7851 - val_loss: 0.4905 - val_acc: 0.7676\n",
      "Epoch 14/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4567 - acc: 0.7903 - val_loss: 0.4832 - val_acc: 0.7750\n",
      "Epoch 15/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4492 - acc: 0.7968 - val_loss: 0.4797 - val_acc: 0.7793\n",
      "Epoch 16/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4421 - acc: 0.8034 - val_loss: 0.4722 - val_acc: 0.7859\n",
      "Epoch 17/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4354 - acc: 0.8081 - val_loss: 0.4676 - val_acc: 0.7903\n",
      "Epoch 18/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4299 - acc: 0.8123 - val_loss: 0.4620 - val_acc: 0.7969\n",
      "Epoch 19/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4246 - acc: 0.8162 - val_loss: 0.4620 - val_acc: 0.7948\n",
      "Epoch 20/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4203 - acc: 0.8193 - val_loss: 0.4549 - val_acc: 0.8035\n",
      "Epoch 21/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4152 - acc: 0.8249 - val_loss: 0.4507 - val_acc: 0.8070\n",
      "Epoch 22/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4117 - acc: 0.8267 - val_loss: 0.4474 - val_acc: 0.8100\n",
      "Epoch 23/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4089 - acc: 0.8293 - val_loss: 0.4513 - val_acc: 0.8076\n",
      "Epoch 24/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4048 - acc: 0.8331 - val_loss: 0.4423 - val_acc: 0.8141\n",
      "Epoch 25/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.4014 - acc: 0.8350 - val_loss: 0.4397 - val_acc: 0.8164\n",
      "Epoch 26/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3993 - acc: 0.8359 - val_loss: 0.4399 - val_acc: 0.8171\n",
      "Epoch 27/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3951 - acc: 0.8395 - val_loss: 0.4359 - val_acc: 0.8198\n",
      "Epoch 28/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3931 - acc: 0.8409 - val_loss: 0.4343 - val_acc: 0.8215\n",
      "Epoch 29/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3902 - acc: 0.8427 - val_loss: 0.4335 - val_acc: 0.8219\n",
      "Epoch 30/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3886 - acc: 0.8438 - val_loss: 0.4335 - val_acc: 0.8221\n",
      "Epoch 31/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3865 - acc: 0.8457 - val_loss: 0.4303 - val_acc: 0.8252\n",
      "Epoch 32/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3845 - acc: 0.8468 - val_loss: 0.4301 - val_acc: 0.8249\n",
      "Epoch 33/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3827 - acc: 0.8481 - val_loss: 0.4295 - val_acc: 0.8255\n",
      "Epoch 34/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3816 - acc: 0.8494 - val_loss: 0.4279 - val_acc: 0.8275\n",
      "Epoch 35/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3799 - acc: 0.8507 - val_loss: 0.4277 - val_acc: 0.8277\n",
      "Epoch 36/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3791 - acc: 0.8509 - val_loss: 0.4280 - val_acc: 0.8261\n",
      "Epoch 37/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3781 - acc: 0.8516 - val_loss: 0.4269 - val_acc: 0.8272\n",
      "Epoch 38/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3768 - acc: 0.8511 - val_loss: 0.4283 - val_acc: 0.8273\n",
      "Epoch 39/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3749 - acc: 0.8515 - val_loss: 0.4260 - val_acc: 0.8285\n",
      "Epoch 40/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3740 - acc: 0.8534 - val_loss: 0.4269 - val_acc: 0.8290\n",
      "Epoch 41/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3724 - acc: 0.8541 - val_loss: 0.4244 - val_acc: 0.8301\n",
      "Epoch 42/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3723 - acc: 0.8547 - val_loss: 0.4242 - val_acc: 0.8313\n",
      "Epoch 43/200\n",
      "12000/12000 [==============================] - 0s 20us/step - loss: 0.3713 - acc: 0.8542 - val_loss: 0.4245 - val_acc: 0.8322\n",
      "Epoch 44/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3693 - acc: 0.8560 - val_loss: 0.4231 - val_acc: 0.8320\n",
      "Epoch 45/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3680 - acc: 0.8568 - val_loss: 0.4229 - val_acc: 0.8323\n",
      "Epoch 46/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3670 - acc: 0.8579 - val_loss: 0.4256 - val_acc: 0.8327\n",
      "Epoch 47/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3667 - acc: 0.8575 - val_loss: 0.4223 - val_acc: 0.8326\n",
      "Epoch 48/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3658 - acc: 0.8589 - val_loss: 0.4221 - val_acc: 0.8331\n",
      "Epoch 49/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3646 - acc: 0.8601 - val_loss: 0.4216 - val_acc: 0.8334\n",
      "Epoch 50/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3643 - acc: 0.8594 - val_loss: 0.4228 - val_acc: 0.8317\n",
      "Epoch 51/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3643 - acc: 0.8595 - val_loss: 0.4216 - val_acc: 0.8341\n",
      "Epoch 52/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3627 - acc: 0.8605 - val_loss: 0.4218 - val_acc: 0.8319\n",
      "Epoch 53/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3618 - acc: 0.8609 - val_loss: 0.4229 - val_acc: 0.8324\n",
      "Epoch 54/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3611 - acc: 0.8612 - val_loss: 0.4208 - val_acc: 0.8349\n",
      "Epoch 55/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3606 - acc: 0.8621 - val_loss: 0.4214 - val_acc: 0.8331\n",
      "Epoch 56/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3604 - acc: 0.8624 - val_loss: 0.4221 - val_acc: 0.8329\n",
      "Epoch 57/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3596 - acc: 0.8618 - val_loss: 0.4214 - val_acc: 0.8334\n",
      "Epoch 58/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3600 - acc: 0.8616 - val_loss: 0.4230 - val_acc: 0.8343\n",
      "Epoch 59/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3594 - acc: 0.8616 - val_loss: 0.4230 - val_acc: 0.8350\n",
      "Epoch 60/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3580 - acc: 0.8624 - val_loss: 0.4218 - val_acc: 0.8337\n",
      "Epoch 61/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3580 - acc: 0.8620 - val_loss: 0.4218 - val_acc: 0.8348\n",
      "Epoch 62/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3576 - acc: 0.8634 - val_loss: 0.4216 - val_acc: 0.8339\n",
      "Epoch 63/200\n",
      "12000/12000 [==============================] - 0s 19us/step - loss: 0.3562 - acc: 0.8635 - val_loss: 0.4223 - val_acc: 0.8334\n",
      "Epoch 64/200\n",
      "12000/12000 [==============================] - 0s 18us/step - loss: 0.3566 - acc: 0.8639 - val_loss: 0.4236 - val_acc: 0.8347\n",
      "auroc: 0.8701155312127072\n",
      "auprc: 0.772648671123347\n",
      "auroc: 0.8700883343891875\n",
      "auprc: 0.7725255067136082\n"
     ]
    }
   ],
   "source": [
    "model, early_stopping_callback, auroc_callback = train_model(model_wrapper = RC_WRAPPER, \n",
    "                                                             aug = None, \n",
    "                                                             curr_seed = 1234,\n",
    "                                                             batch_size = 500,\n",
    "                                                             x = x_train, \n",
    "                                                             y = y_train, \n",
    "                                                             val_data = (x_val, y_val))\n",
    "save_all(filepath = \"path/to/file\", model_arch = \"model_name\", curr_seed = curr_seed,\n",
    "         callback = auroc_callback, model = model, val_data = (x_val, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf1.15.2]",
   "language": "python",
   "name": "conda-env-tf1.15.2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
